{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt","metadata":{"id":"FZEco2HK6D57"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_SEED = 0xdeadbeef","metadata":{"id":"a3nCUqopXHwv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lab 02: Linear Regression","metadata":{"id":"jjTkUw7BWulH"}},{"cell_type":"markdown","source":"For the first tasks, we will work with synthetic univariate data.\nWe generate $100$ features $x_i \\in [-1, 1]$ as `x` and two different\nregression targets `y1` and `y2`.","metadata":{"id":"gNnZUk36Xz7_"}},{"cell_type":"code","source":"data_rng = np.random.default_rng(RANDOM_SEED)\nn = 100\nx = 2 * data_rng.random(n) - 1  # create n points between -1 and 1\n\n# setup synthetic y1\ntrue_offset = 0.5\ntrue_slope = 1.25\nnoise = data_rng.normal(loc=0., scale=0.25, size=(n,))\n\ny1 = true_offset + true_slope * x + noise\n\n\n# setup synthetic y2\ny2  = true_offset + np.sin(np.pi * x) + noise","metadata":{"id":"Ojta777H2ulb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 1: Scatter Plot","metadata":{"id":"ntdpTWzqZqAU"}},{"cell_type":"markdown","source":"In the next cell, we show you how you can use `plt.scatter` to create scatter-plots.\n\nA scatter plot is a graphical representation that displays individual data points based on two variables, with one variable plotted along the x-axis and the other plotted along the y-axis. It's commonly used to observe and show relationships between two numeric variables.\nPlot `x` against the target variable `y1`.\n\nThe simplest way to create a scatter-plot in `matplotlib` is by calling `plt.scatter(x, y)` where `x` is a list or array of x-coordinates and `y` is a list or array of y-coordinates.","metadata":{"id":"JbNJ7WhzbAtm"}},{"cell_type":"code","source":"# Let us create a scatter-plot of x and y1\nplt.scatter(x, y1)","metadata":{"id":"KgN-CimVK9vl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the next cell, we re-create the same plot but also label the axes, which is generally a good practice.\n\nIn `matplotlib` it is common to build a plot incrementally by calling many functions (such as `plt.xlabel` and `plt.ylabel` here), before displaying the result using `plt.show()`.","metadata":{"id":"5njACsM7LOMp"}},{"cell_type":"code","source":"plt.scatter(x, y1)\nplt.xlabel(\"x\")\nplt.ylabel(\"y1\")\nplt.show()","metadata":{"id":"MxYMdhfxyYAd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ðŸš¨ Task 1A (1 Point) ðŸš¨\n\nYour turn:\n\n* create a scatter-plot of `x` and `y2`.\n* Study the plot: do you think the relationship between `x` and `y2` is linear?","metadata":{"id":"NFTpeQMrL4mx"}},{"cell_type":"code","source":"# TODO","metadata":{"id":"HpzwoBdQDd-d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ“¢ **<mark>On Moodle</mark>** ðŸ“¢\n\n* Report whether the relationship between `x` and `y2` is linear.","metadata":{"id":"-VBXqkBMczI1"}},{"cell_type":"markdown","source":"# Task 2: Univariate Linear Regression","metadata":{"id":"rbjhdwFceHlL"}},{"cell_type":"markdown","source":"You will now implement Linear Regression with a single variable. In class you have seen that the underlying model is: $y = \\theta_0 + \\theta_1x$.\n\nYou also derived the closed formula for $\\theta_0$ and $\\theta_1$:\n\n* $\\hat{\\theta}_1 = \\frac{\\sum_{i=1}^{m} (x_i - \\mu(x))(y_i - \\mu(y))}{\\sum_{i=1}^{m}(x_i - \\mu(x))^2}$\n* $\\hat{\\theta}_0 = \\mu(y) - \\hat{\\theta}_1\\mu(x)$","metadata":{"id":"ucnYGKbmecz_"}},{"cell_type":"markdown","source":"## ðŸš¨ Task 2A (2 Points) ðŸš¨\n\nIn the following cell, implement the `.fit` and `.predict` methods:\n* In the `.predict` method you will have to apply the model to the input `x`\n* In the `.fit` method you will have to compute $\\hat{\\theta}_0$ and $\\hat{\\theta}_1$.","metadata":{"id":"SlMsQokKdksd"}},{"cell_type":"code","source":"class UnivariateLinearRegression:\n\n  def __init__(self):\n    self.theta_0: float = 0.\n    self.theta_1: float = 0.\n\n  def predict(self, x):\n    y_pred = ...  # TODO\n    return y_pred\n\n  def fit(self, x, y):\n    # TODO\n    self.theta_0 = ...\n    self.theta_1 = ...\n\n    return self","metadata":{"id":"qS0Oa5Btgk74"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ“¢ **<mark>On Moodle</mark>**: ðŸ“¢\n\n* Make a snapshot, or copy and submit the code you have written in the cell above.","metadata":{"id":"ySKlBT7dd1hS"}},{"cell_type":"markdown","source":"Now we fit the linear model to `x` and the target `y1`:\n\n* Create an instance of the class `UnivariateLinearRegression`\n* fit the model using its `.fit` method\n* get the predicted values, using `.predict`\n","metadata":{"id":"9LzenH1UhLOs"}},{"cell_type":"code","source":"lin_reg_uni = UnivariateLinearRegression()\nlin_reg_uni.fit(x, y1)\ny_pred = lin_reg_uni.predict(x)","metadata":{"id":"hdIrwBLG1I_8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the next cell, we provide a helper function to visualize your fitted linear model, based on `x`, the true values of `y` (`y_true`) and the predicted values of `y` (`y_pred`):","metadata":{"id":"elE3OfjHjBRO"}},{"cell_type":"code","source":"def plot_model(x, y_pred, y_true):\n  # scatter plot of the true data points\n  plt.scatter(x, y_true)\n  # plot the fitted line\n  plt.plot(x, y_pred, c=\"r\")\n  # label axes\n  plt.xlabel(\"x\")\n  plt.ylabel(\"y\")\n  plt.show()","metadata":{"id":"T0eKDuRt1YOF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We use `plot_model` to visualize to outcome of our linear regression for `x` and `y1`.","metadata":{"id":"pwxsx5lGOx3O"}},{"cell_type":"code","source":"plot_model(x=x, y_pred=y_pred, y_true=y1)","metadata":{"id":"2goCBVKLPBHm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we repeat the same steps for `x` and `y2`. Inspect the plot and reflect on your answer to Task 2A.","metadata":{"id":"tt2RnAwAG1n9"}},{"cell_type":"code","source":"lin_reg_uni = UnivariateLinearRegression()\nlin_reg_uni.fit(x, y2)\ny_pred = lin_reg_uni.predict(x)\n\nplot_model(x, y_pred, y2)","metadata":{"id":"Ccq3GI17Ga2x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 3: Multivariate Linear Regression using the Normal Equation","metadata":{"id":"Ta5zAjsuQFlR"}},{"cell_type":"markdown","source":"In the next cell, we provide a function to generate synthetic data for\nmultivariate linear regression.","metadata":{"id":"tgVABRUlWwo6"}},{"cell_type":"code","source":"def create_random_data(m: int, n: int, random_seed: int = RANDOM_SEED):\n  \"\"\"\n  m: number of samples\n  n: number of dimensions\n  random_seed: seed to initialize random number generator\n  \"\"\"\n  rng = np.random.default_rng(random_seed)\n  # random data\n  X = rng.standard_normal(size=(m, n))\n  # random true model parameters\n  theta = rng.standard_normal(n)\n  # random noise\n  noise = rng.normal(loc=0., scale=.25, size=m)\n  # observed y values\n  y = X @ theta + noise\n  return X, y\n\n# create synthetic dataset with 100 observations and 10 dimensions\nX, y = create_random_data(100, 10)","metadata":{"id":"eEm4eB2GS1gJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In class you have seen that the underlying model for multivariate linear regression is: $y = X\\theta$. Here $X \\in \\mathbb{R}^{m, n}$, $\\theta \\in \\mathbb{R}^{n}$, and $y \\in \\mathbb{R}^{m}$.\n\nWe also derived a closed formula for $\\theta$:\n\n $\\hat{\\theta} = (X^{T}X)^{-1}X^{T}y$\n\nThis is known as the *normal equation*.","metadata":{"id":"72ecXwtMXorm"}},{"cell_type":"markdown","source":"The normal equation can be used to solve univariate and also multivariate linear regression problems, and we have shown that it yields optimal parameters.\n\n","metadata":{"id":"nDb5iT2DbCQT"}},{"cell_type":"markdown","source":"In the next cell we implement the normal equation $\\hat{\\theta} = (X^{T}X)^{-1}X^{T}y$ and apply it to our data `X` and `y`.\n\n`numpy` reminder:\n* the transpose of `X` is written `X.T`\n* matrix multiplication is written with the `@` symbol, e.g. `A @ B`.\n* you can compute the inverse of a matrix `A` using `np.linalg.inv(A)`. However, it is more numerically stable (and yes, this can really make a difference in practice!) to use a method such as `pinv` or `solve`, as noted below.","metadata":{"id":"8dw4O4zzblU7"}},{"cell_type":"code","source":"theta = (np.linalg.inv(X.T @ X) @ X.T) @ y","metadata":{"id":"r6Af3VQ-Tqco"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Computing the matrix inverse as part of a larger expression*: when solving the normal equation, we don't actually care about the inverse $(X^{T}X)^{-1}$ by itself; rather, we care about its value <em>when multiplied by another vector</em>. In particular, the expression $(X^{T}X)^{-1}X^{T}$ is also known as the [Moore-Penrose Pseudoinverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse) of $X$ and can be computed directly using `np.linalg.pinv(X)`, which is generally more efficient. Alternatively, you can solve the normal equation as `np.linalg.solve(X.T @ X, X.T @ y)`.","metadata":{"id":"z0CvpicyfLi5"}},{"cell_type":"markdown","source":"In the next cell, we provide a helper function to create a residual plot\nbased on the true values of `y` (`y_true`) and the predicted values of `y` (`y_pred`).","metadata":{"id":"ozPqV-ekc3sX"}},{"cell_type":"code","source":"def residual_plot(y_true, y_pred):\n  residual = y_pred - y_true\n  plt.scatter(y_true, residual)\n  plt.xlabel(\"y\")\n  plt.ylabel(\"residual\")\n  plt.title(\"Residual Plot\")\n  plt.show()","metadata":{"id":"_hjDkSzedCVc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below we compute the predicted values of `y` based on the value of $\\theta$ you computed using the normal equation. Then we plot the residuals using `residual_plot`.","metadata":{"id":"wPgYF6W2damr"}},{"cell_type":"code","source":"y_pred = X @ theta\n\nresidual_plot(y_true=y, y_pred=y_pred)","metadata":{"id":"t1r2mDlCdQNs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance of Normal Equation\n\nMax Clever has seen the slides for next lecture already â€“ where we will discuss alternative methods such as \"gradient descent\" for linear regression.\n\nNow he wonders: *Why do we need other algorithms, when the normal equation solves the problem already?*\n\nTo answer this question, we will now explore how the runtime of computing the normal equation depends on the input size $n$ and $m$.\n\nIn the next cell, we provide a skeleton to measure the runtime of computing the normal equation depending on the problem size n*m.\n\n## ðŸš¨ Task 3A (2 Point) ðŸš¨\n* fill in the blanks in the code below\n* run the code and explore different values for $m$. For which values of $m$ is the running time still below 30min?\n","metadata":{"id":"sIQLVzb3gwAR"}},{"cell_type":"code","source":"import time\nsizes = []\ntimes = []\nn = 1000\nfor m in [10, 50, 100, 200, 250, 500, 1000]:\n  X, y = ... # TODO create a dataset with m samples and n dimensions, we provide a helper function for this!\n\n  start_time = time.monotonic()\n  # enter the code you want to time here\n  elapsed = time.monotonic() - start_time\n\n  problem_size = ...  # TODO what is the input size of the problem\n\n  sizes.append(problem_size)\n  times.append(elapsed)\n\nplt.scatter(sizes, times)\nplt.xlabel('Problem-Size')\nplt.ylabel('Runtime (s)')\nplt.show()","metadata":{"id":"-FZizKeAob-n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ“¢ **<mark>On Moodle</mark>** ðŸ“¢\n\nAnswer the following question:\n\n* Plot with different problem sizes\n* Which problem size yields a running time of approximately 30 minutes?\n","metadata":{"id":"zzn9IONOhZvx"}},{"cell_type":"markdown","source":"## ðŸš¨ Task 3B (2 Point) ðŸš¨\n\nWe now explore the impact of the number of features, $n$, on the running time:\n\n* Modify your solution to Task 3A to measure the runtime dependence on the number of features $n$ instead of the number of samples $m$.\n* What happens if you use large values for $n$, e.g. $n = 100'000$?","metadata":{"id":"cx-di2EypWy6"}},{"cell_type":"code","source":"# TODO","metadata":{"id":"cttPLHu6prPH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ“¢ **<mark>On Moodle</mark>** ðŸ“¢\n\nAnswer the following question:\n\n* Upload your plot with a \"very large\" maximal value for $n$.","metadata":{"id":"cnwQb2JKpwL_"}},{"cell_type":"markdown","source":"## OPTIONAL QUESTIONS\n\n* Do your responses to Tasks 3A and 3B change if you use `np.linalg.pinv(X)`?\n* Probably your plots for number of samples $m$ and number of features $n$ look very alike. Can you explain why?","metadata":{"id":"eBAW0JCgrCGf"}},{"cell_type":"markdown","source":"# Task 4: Multivariate Linear Regression using `scikit-learn`","metadata":{"id":"dgrNtwsPyigH"}},{"cell_type":"markdown","source":"In this task we will apply linear regression to non-synthetic data.\nThe variable `X` is a `pandas` `Dataframe` containing features and `y` contains\nthe target. Read through the description to get an idea of the different variables.","metadata":{"id":"_sPWegXCg2y1"}},{"cell_type":"code","source":"from sklearn.datasets import load_diabetes\n\ndata = load_diabetes(as_frame=True)\n\nX = data['data']\ny = data['target']\ndescription = data['DESCR']\n\nprint(description)","metadata":{"id":"djGUQ3kVx9ob"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the next cell, we will fit a linear regression model on this diabetes dataset\nusing the implementation provided by the popular `scikit-learn` library.\n\nTheir [implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) is contained in the `sklearn.linear_model.LinearRegression` class. The most important methods of any `sklearn` model are `.fit` and `.predict`. You will see them a lot in future labs.\n\nThe `.fit(X, y)` method trains the linear regression model and `.predict(X)` return the model's predictions for the data `X`.\n\nYou can see them in action in the next cell.","metadata":{"id":"byOVt9t9_2c7"}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\ny_pred = lin_reg.predict(X)\n\nresidual_plot(y_true=y, y_pred=y_pred)","metadata":{"id":"G4AktC189PAc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The numeric entries of the estimated parameter vector $\\theta$ tell us something about the strength and direction of the relationship between the variables in `X` and the target `y`.\n\n\nThe estimated parameters $\\theta$ of the linear model can be found in the `.coef_` member variable. The feature names can be found in the `.feature_names_in_` member variable. They are the same as the names of the columns of `X` and should be in the same order.","metadata":{"id":"qQUdYHOXpeLd"}},{"cell_type":"markdown","source":"In the next code cell, we will plot the entries of $\\theta$ paired with their corresponding feature name. We will also print out the same information.","metadata":{"id":"y8pyPAMwl5c-"}},{"cell_type":"markdown","source":"## ðŸš¨ Task 4A (3 Points) ðŸš¨\n\nStudy the plot and printed output of the next cell and answer the following questions:\n\n* Which are the 3 most influential features?\n* How do you interpret the sign of the coefficients?\n* If you had to exclude 1 feature, which one would you select and why?","metadata":{"id":"3J8vO5FemPQw"}},{"cell_type":"code","source":"thetas = lin_reg.coef_\nfeature_names = lin_reg.feature_names_in_\n\nplt.bar(feature_names, thetas)\nplt.xticks(rotation=90)\nplt.ylabel(\"theta\")\nplt.show()\n\nprint()\nfor th, name in zip(thetas, feature_names):\n  print(f\"{name}\\t{th}\")","metadata":{"id":"odXnubfHqrfc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ“¢ **<mark>On Moodle</mark>** ðŸ“¢\n\n* Report your answers to the 3 questions.","metadata":{"id":"gmrnK-EkmgFW"}}]}